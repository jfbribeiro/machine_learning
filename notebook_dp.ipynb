{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "# TOC<a class=\"anchor\"><a id='toc'></a></b><br>\n",
    "* [<font color='#E8800A'>Naive Bayes</font>](#first-bullet) <br>\n",
    "- [<font color='#E8800A'>Logistic Regression</font>](#second-bullet)<br>\n",
    "- [<font color='#E8800A'>KNN</font>](#third-bullet)<br>\n",
    "- [<font color='#E8800A'>Support Vector Machines</font>](#fourth-bullet)<br>\n",
    "- [<font color='#E8800A'>Decision Trees</font>](#fifth-bullet)<br>\n",
    "- [<font color='#E8800A'>Random forest</font>](#sixth-bullet)<br>\n",
    "- [<font color='#E8800A'>Boosted Trees</font>](#seventh-bullet)<br> \n",
    "- [<font color='#E8800A'>Neural Networks</font>](#eighth-bullet)<br> \n",
    "- [<font color='#E8800A'>Ensembles</font>](#ninth-bullet)<br>   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score,\\\n",
    "RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, \\\n",
    "GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "\n",
    "%pip install boruta\n",
    "from boruta import BorutaPy\n",
    "\n",
    "%pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%pip install pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "%pip install openpyxl\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions \n",
    "datain_path = 'data/'\n",
    "src_path = 'src/'\n",
    "\n",
    "\n",
    "explorations_path = 'explorations/'\n",
    "submissions_path = 'submissions/'\n",
    "\n",
    "paths = [explorations_path, submissions_path]\n",
    "for path in paths:\n",
    "    if not os.path.exists(path): \n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': 'Train.xlsx',\n",
    "    'test':'Test.xlsx', \n",
    "    'both': {\n",
    "        'train': 'Train.xlsx',   \n",
    "        'test':'Test.xlsx',\n",
    "    } \n",
    "}\n",
    "\n",
    "#datasets = pd.DataFrame(datasets, columns=['name', 'path']).set_index('name')\n",
    "\n",
    "dataset_name = 'both'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'both': \n",
    "    data = pd.DataFrame()\n",
    "    for dataset_path in datasets[dataset_name].values(): \n",
    "        tmp = pd.read_excel(os.path.join(datain_path, dataset_path))\n",
    "        data = pd.concat([data, tmp])\n",
    "\n",
    "else:    \n",
    "    dataset_path = datasets[dataset_name]\n",
    "    data = pd.read_excel(os.path.join(datain_path, dataset_path))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## profile report\n",
    "\n",
    "profile = ProfileReport(\n",
    "    data,\n",
    "    title='Raw data',\n",
    "    minimal=False, \n",
    "    correlations={\n",
    "    \"pearson\": {\"calculate\": True},\n",
    "    \"spearman\": {\"calculate\": False},\n",
    "    \"kendall\": {\"calculate\": False},\n",
    "    \"phi_k\": {\"calculate\": False},\n",
    "    \"cramers\": {\"calculate\": False},\n",
    "    }\n",
    ")\n",
    "profile.to_file(os.path.join(explorations_path, 'profile_data_raw.html'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature=10\n",
    "\n",
    "def calc_elbowdata(data, base_col): \n",
    "    plotdata = data.copy().loc[~data.Income.isna(),:].groupby(base_col).size().sort_values(ascending=False)\n",
    "    plotdata = pd.DataFrame(plotdata / plotdata.sum()).cumsum().rename(columns={0:'nobs_rel'})\n",
    "    return plotdata\n",
    "\n",
    "def get_feature_imp_by_expl(data, base_col, n_feature=n_feature): \n",
    "    \n",
    "    # make sure every combination of levels exist, fill with 0 if no obs\n",
    "    base = data[base_col].unique()\n",
    "    Income = [0, 1]\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [base, Income],\n",
    "        names=[base_col, 'Income']\n",
    "    )\n",
    "\n",
    "    pd1 = pd.DataFrame(index=idx)\n",
    "    \n",
    "\n",
    "    a = data.groupby([base_col, 'Income']).size().to_frame().rename(columns={0:'nobs'})\n",
    "    \n",
    "    a = pd.concat([pd1, a], axis=1)\n",
    "    a.loc[a.nobs.isna(), 'nobs'] = 0\n",
    "    \n",
    "    a['nobs_rel'] = a.groupby(level=base_col).transform(lambda x: x / (x[0] + x[1]))\n",
    "    value_cols = a.columns.to_list()\n",
    "    a.reset_index(inplace=True)\n",
    "    \n",
    "    # top Features by nobs: \n",
    "    topFeat = data.groupby(base_col).size().to_frame().rename(columns={0:'nobs'})\\\n",
    "        .sort_values('nobs', ascending=False).iloc[0:n_feature,:]\\\n",
    "        .index.to_list()\n",
    "    \n",
    "    a.sort_values(['nobs', base_col], ascending=False, inplace=True)\n",
    "    \n",
    "    #print('len(topFeat)', len(topFeat))\n",
    "    #print('len(a)', len(a))\n",
    "    #print('n_feature', n_feature)\n",
    "    #print('a[base_col].nunique()', a[base_col].nunique())\n",
    "\n",
    "    if len(topFeat) < a[base_col].nunique(): \n",
    "        print(f'***Features Filtered to top_{n_feature} by nobs!***')\n",
    "    #print(a[base_col].nunique())\n",
    "\n",
    "    a = a.loc[a[base_col].isin(topFeat),:]\n",
    "    return a, value_cols\n",
    "\n",
    "def plot_feature_imp_by_expl(data, base_col, saveplots): \n",
    "    \n",
    "    a, value_cols = get_feature_imp_by_expl(data, base_col)\n",
    "    \n",
    "    value_cols.remove('nobs')\n",
    "    print(value_cols)\n",
    "    n_plots = len(value_cols) + 1\n",
    "\n",
    "    fig, ax = plt.subplots() #, figsize=(20,7)\n",
    "    #sns.barplot(data=a, x=base_col, y='nobs', hue='Income', ax=ax)#.set_title(col) # [0:10]\n",
    "    #ax.tick_params(labelrotation=45)\n",
    "    plotdata = calc_elbowdata(data, base_col)\n",
    "    sns.lineplot(data=plotdata, y=plotdata.index, x='nobs_rel', ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if saveplots: \n",
    "        plt.savefig(os.path.join(explorations_path, 'feature_imp_by_expl_abs.png'), dpi=200)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(ncols = n_plots, gridspec_kw={'width_ratios': [3,1]}) #, figsize=(20,7)\n",
    "    for i, col in enumerate(value_cols): \n",
    "        sns.barplot(data=a, x=base_col, y=col, hue='Income', ax=ax[i])#.set_title(col) # [0:10]\n",
    "        ax[i].tick_params(labelrotation=45)\n",
    "\n",
    "    sns.countplot(data=data, x='Income', ax=ax[n_plots-1])\n",
    "    plt.tight_layout()\n",
    "    if saveplots: \n",
    "        plt.savefig(os.path.join(explorations_path, 'feature_imp_by_expl_rel.png'), dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "def get_target_ratio(data):  \n",
    "    a = data.groupby(['Income']).size().to_frame().rename(columns={0:'nobs'})\n",
    "    a['nobs_rel'] = a.transform(lambda x: x / (x[0] + x[1]))\n",
    "    value_cols = a.columns.to_list()\n",
    "    a.reset_index(inplace=True)\n",
    "    return a.loc[a.Income == 1, 'nobs_rel'].to_list()[0]\n",
    "\n",
    "\n",
    "def get_feature_imp_by_target_ratio(data, base_col, weighted=False, saveplots=False): \n",
    "\n",
    "    target_ratio = get_target_ratio(data)\n",
    "    target_ratio\n",
    "                                            \n",
    "    a, _ = get_feature_imp_by_expl(data, base_col, n_feature=100)\n",
    "    \n",
    "    #########\n",
    "    nObsPerFeatClass =  data.groupby([base_col]).size().to_frame().rename(columns={0:'nobs'})\n",
    "                           \n",
    "\n",
    "    ratio_per_level = a.loc[a.Income == 1, [base_col,'nobs_rel']]\\\n",
    "        .set_index(base_col)\\\n",
    "        .rename(columns={'nobs_rel':'class1_ratio'})\n",
    "\n",
    "    ratio_per_level = pd.concat([ratio_per_level, nObsPerFeatClass], axis=1)\n",
    "    #min_max_scaler_obs = MinMaxScaler()\n",
    "    ratio_per_level['nobs_rel'] = ratio_per_level.nobs / sum(ratio_per_level.nobs)\n",
    "\n",
    "\n",
    "    \n",
    "    ratio_per_level['diff_to_target'] = ratio_per_level['class1_ratio'] - target_ratio\n",
    "    ratio_per_level['diff_to_target_dir'] = ['neg' if obs < 0 else 'pos' for obs in ratio_per_level['diff_to_target']]\n",
    "    \n",
    "    if weighted: \n",
    "        weights = np.power(ratio_per_level['nobs_rel'], 1./3)\n",
    "    else: \n",
    "        weights = 1\n",
    "        \n",
    "    ratio_per_level['diff_to_target_abs'] = abs(ratio_per_level['diff_to_target']) * weights\n",
    "    \n",
    "    #print(ratio_per_level)\n",
    "\n",
    "    ratio_per_level.sort_values('diff_to_target_abs', ascending=False, inplace=True)\n",
    "    ratio_per_level['diff_to_target_abs_cumsum'] = ratio_per_level.diff_to_target_abs.cumsum()\n",
    "    ratio_per_level\n",
    "\n",
    "\n",
    "    x = ratio_per_level['diff_to_target_abs_cumsum'].values.reshape(-1, 1) #df.values #returns a numpy array\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    ratio_per_level['diff_to_target_abs_cumsum_scaled'] = min_max_scaler.fit_transform(x)\n",
    "\n",
    "    print('TargetClass1_ratio', target_ratio)\n",
    "    diff_to_target_df = ratio_per_level.copy()[['diff_to_target_dir', 'diff_to_target_abs']]\n",
    "    diff_to_target_df.diff_to_target_abs = round(diff_to_target_df.diff_to_target_abs, 4)\n",
    "    print(diff_to_target_df)\n",
    "    if saveplots:\n",
    "        diff_to_target_df.to_excel(os.path.join(explorations_path, 'diff_to_target_df.xlsx'))\n",
    "\n",
    "    \n",
    "    ratio_per_level.index.set_names(base_col, inplace=True)\n",
    "    return ratio_per_level\n",
    "\n",
    "\n",
    "def plot_feature_imp_by_target_ratio(data, base_col, weighted=False, saveplots=False): \n",
    "\n",
    "    r = get_feature_imp_by_target_ratio(data, base_col, weighted, saveplots=saveplots)\n",
    "\n",
    "    sns.lineplot(data=r, y=r.index, x='diff_to_target_abs_cumsum_scaled')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if saveplots: \n",
    "        plt.savefig(os.path.join(explorations_path, 'feature_imp_by_target_ratio.png'), dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_feature_imp_by_tree(data, base_col, n_feature=n_feature, saveplots=False): \n",
    "    # prepare\n",
    "    onehot = OneHotEncoder()\n",
    "    X_train_cat = data.loc[:,[base_col]]\n",
    "    #X_train_cat = data[base_col]\n",
    "\n",
    "    X_train_onehot = onehot.fit_transform(X_train_cat)\n",
    "    X_train_onehot_df = pd.DataFrame(X_train_onehot.toarray(), columns=onehot.get_feature_names())\n",
    "    X_train_onehot_df\n",
    "\n",
    "    X_train_onehot_df = pd.get_dummies(data[base_col], prefix=base_col)\n",
    "\n",
    "    # train\n",
    "    dt_gini = DecisionTreeClassifier(random_state = 1)\n",
    "    X_train = X_train_onehot_df#.drop(columns=['x0_Africa','x0_Europe', 'x0_Oceania'])\n",
    "    y_train = data.Income\n",
    "\n",
    "\n",
    "    dt_gini.fit(X_train, y_train) # data[base_col]\n",
    "    print('Score:', dt_gini.score(X_train, y_train))\n",
    "\n",
    "    #dt_gini.feature_importances_\n",
    "    #tree.plot_tree(dt_gini)\n",
    "\n",
    "    #plt.barh(onehot.get_feature_names(), dt_gini.feature_importances_)\n",
    "\n",
    "    #print(dt_gini.feature_importances_)\n",
    "    sorted_idx = dt_gini.feature_importances_.argsort()#[0:10]\n",
    "    plotdata = pd.DataFrame({\n",
    "        'Feature': X_train.columns[sorted_idx], \n",
    "        'Importance': dt_gini.feature_importances_[sorted_idx]}).sort_values('Importance', ascending=False)\n",
    "    #plt.barh()\n",
    "    #print(plotdata)\n",
    "    sns.barplot(data=plotdata.iloc[0:n_feature,:], x='Importance', y='Feature')\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if saveplots: \n",
    "        plt.savefig(os.path.join(explorations_path, 'feature_imp_by_tree.png'), dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_feature_imp(data, base_col, force_barplot=True, weighted=False, saveplots=False): \n",
    "    print('Class distributions')\n",
    "    if (data[base_col].nunique() < 6) | force_barplot:\n",
    "        n_plots = 2\n",
    "        plot_feature_imp_by_expl(data, base_col, saveplots=saveplots)\n",
    "    else: \n",
    "        n_plots = 1\n",
    "        \n",
    "    print('\\nElbow')        \n",
    "    plot_feature_imp_by_target_ratio(data, base_col, weighted, saveplots=saveplots)\n",
    "    \n",
    "    print('\\nDecision Tree')\n",
    "    plot_feature_imp_by_tree(data, base_col, saveplots=saveplots)\n",
    "    \n",
    "def levels_equal(data, base_col):\n",
    "    train_levels = np.sort(data.loc[~data.Income.isna(), base_col].unique()).tolist()\n",
    "    test_levels = np.sort(data.loc[data.Income.isna(), base_col].unique()).tolist()\n",
    "    \n",
    "    equal = train_levels == test_levels\n",
    "    if not equal: \n",
    "        test_levels_df = pd.DataFrame({\n",
    "            'test_levels': test_levels\n",
    "        })\n",
    "\n",
    "        train_levels_df = pd.DataFrame({\n",
    "            'train_levels': train_levels\n",
    "        })\n",
    "\n",
    "        compare = pd.merge(left=train_levels_df, right=test_levels_df, how='outer', left_on='train_levels', right_on='test_levels')\n",
    "        print(compare.loc[(compare.train_levels.isna()) | (compare.test_levels.isna()) ])\n",
    "\n",
    "        print(f'Levels of \"{base_col}\" differ between test and train set')\n",
    "        #raise ValueError(f'Levels of \"{base_col}\" differ between test and train set')\n",
    "    else: \n",
    "        print('Levels ok')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init \n",
    "cols_to_drop = []\n",
    "cols_to_onehot = []\n",
    "cols_numeric = []\n",
    "cols_bool = []\n",
    "\n",
    "\n",
    "\n",
    "# prep\n",
    "pred_config = {\n",
    "    'cardinality': 'original' # low, medium, high, original\n",
    "} \n",
    "\n",
    "cardinality = pred_config['cardinality']\n",
    "print('cardinality:', cardinality)\n",
    "\n",
    "error_log = {'cleaning': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract gender from name?!\n",
    "base_col = 'Name'\n",
    "target_col = 'male'\n",
    "\n",
    "salutation = data[base_col].str.split(' ', n=1, expand=True)[0]\n",
    "if salutation.nunique() != 3: \n",
    "    raise ValueError('Unexpected levels of salutation')\n",
    "    \n",
    "print(salutation.value_counts())\n",
    "\n",
    "#gender = ['male' if s == 'Mr.' else 'female' for s in salutation]\n",
    "#data['gender'] = gender\n",
    "\n",
    "male = [1 if s == 'Mr.' else 0 if s in ['Mrs.', 'Miss'] else np.nan for s in salutation]\n",
    "data[target_col] = male\n",
    "\n",
    "if data.male.isna().sum() > 0: \n",
    "    raise Warning('NAs instroduced')\n",
    "\n",
    "\n",
    "sns.countplot(data=data, hue=data.Income, x=target_col)#.set_title(col)\n",
    "plt.show()\n",
    "    \n",
    "cols_to_drop.append(base_col)\n",
    "cols_bool.append(target_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute age from Birthday\n",
    "\n",
    "# clean whitespaces\n",
    "data.Birthday = data.Birthday.str.replace(' ', '')\n",
    "# define date format\n",
    "dob_format = '%B%d,%Y'\n",
    "\n",
    "# transform Birthday to datetime, catching the leap year error \n",
    "\n",
    "## helper fct to subtract one day from datetime if error occurs\n",
    "def subone(obj):\n",
    "    val = int(obj.group(0))\n",
    "    return str(val-1)\n",
    "\n",
    "## init and loop over dates\n",
    "dob = []\n",
    "warn_log = []\n",
    "for i, d in enumerate(data.Birthday): \n",
    "    try: \n",
    "        dob.append(datetime.strptime(d, dob_format).date())\n",
    "\n",
    "    except ValueError as e: \n",
    "        if str(e) == 'day is out of range for month': \n",
    "            dt = datetime.strptime(re.sub('\\d{1,2}', subone, d, count=1), dob_format).date()\n",
    "            warn_log.append((d, dt))\n",
    "            dob.append(dt)\n",
    "        else: \n",
    "            raise NotImplementedError('Do not know how to deal with that error!')\n",
    "            dt = np.nan\n",
    "            warn_log.append((d, dt))\n",
    "            dob.append(dt)\n",
    "        \n",
    "# add age column \n",
    "data['age'] = [np.floor((datetime.strptime('2048-12-31', '%Y-%m-%d').date() - d).days / 365.2425) for d in dob]\n",
    "\n",
    "# inspect\n",
    "sns.histplot(data, x='age')\n",
    "plt.show()\n",
    "print('Min age:' , min(data.age))\n",
    "\n",
    "# drop date col \n",
    "cols_to_drop.append('Birthday')\n",
    "cols_numeric.append('age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[~data.Income.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'Native Continent' to bin \n",
    "base_col = 'Native Continent'\n",
    "#sns.countplot(data=data, hue=data.Income, x=base_col)#.set_title(col)\n",
    "#plt.show()\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False, saveplots=False)\n",
    "levels_equal(data, base_col)\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality in ['low', 'medium']:\n",
    "        target_col = 'from_europe_or_asia'\n",
    "        #data['from_europe'] = [1 if a == 'Europe' else 0 for a in data[base_col]]\n",
    "        data[target_col] = [1 if a in ['Europe', 'Asia'] else 0 for a in data[base_col]]\n",
    "        cols_bool.append(target_col)\n",
    "    elif cardinality == 'original':\n",
    "        target_col = 'native_continent'\n",
    "        data[target_col] = data[base_col]\n",
    "        cols_to_onehot.append(target_col)\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Marital Status\n",
    "base_col = 'Marital Status'\n",
    "#target_col = 'marital_status'\n",
    "\n",
    "data[base_col].value_counts()\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False)\n",
    "levels_equal(data, base_col)\n",
    "\n",
    "try: \n",
    "    if cardinality == 'low': \n",
    "        target_col = 'maritalStatus_married'\n",
    "        data[target_col] = [1 if a in ['Married', 'Married - Spouse in the Army'] else 0 for a in data[base_col]]\n",
    "        cols_bool.append(target_col)\n",
    "        \n",
    "    elif cardinality == 'medium': \n",
    "        target_col = 'maritalStatus'\n",
    "        mapping = {\n",
    "            'Married':'Married',\n",
    "            'Single':'Single',\n",
    "            'Divorced':'Divorced',\n",
    "            'Separated':'Separated',\n",
    "            'Widow':'Widow',\n",
    "            'Married - Spouse Missing':'SpouseMissing',\n",
    "            'Married - Spouse in the Army':'Married'\n",
    "        }\n",
    "\n",
    "        data[target_col] = data[base_col].map(mapping)\n",
    "        cols_to_onehot.append(target_col)\n",
    "        \n",
    "    elif cardinality == 'original': \n",
    "        target_col = 'maritalStatus'\n",
    "        mapping = {\n",
    "            'Married':'Married',\n",
    "            'Single':'Single',\n",
    "            'Divorced':'Divorced',\n",
    "            'Separated':'Separated',\n",
    "            'Widow':'Widow',\n",
    "            'Married - Spouse Missing':'SpouseMissing',\n",
    "            'Married - Spouse in the Army':'MarriedArmy'\n",
    "        }\n",
    "\n",
    "        data[target_col] = data[base_col].map(mapping)\n",
    "        cols_to_onehot.append(target_col)\n",
    "\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "    \n",
    "#sns.countplot(data=data, x=target_col)\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lives with\n",
    "base_col = 'Lives with'\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False, saveplots=True)\n",
    "levels_equal(data, base_col)\n",
    "\n",
    "try: \n",
    "    if(cardinality == 'low'): \n",
    "        target_col = 'household_livesWithPartner'\n",
    "        data[target_col] = [1 if a in ['Wife', 'Husband'] else 0 for a in data[base_col]]\n",
    "        cols_bool.append(target_col)\n",
    "    elif(cardinality == 'medium'): \n",
    "        target_col = 'household'\n",
    "        mapping = {\n",
    "            'Wife': 'Partner',\n",
    "            'Other Family': 'Family',\n",
    "            'Children': 'Children',\n",
    "            'Alone': 'Alone',\n",
    "            'Husband': 'Partner',\n",
    "            'Other relatives': 'Family'\n",
    "        }\n",
    "\n",
    "        print(mapping)\n",
    "\n",
    "        data[target_col] = data[base_col].map(mapping)\n",
    "        cols_to_onehot.append(target_col)\n",
    "    elif(cardinality == 'original'): \n",
    "        target_col = 'household'\n",
    "        mapping = {\n",
    "            'Wife': 'Wife',\n",
    "            'Other Family': 'Family',\n",
    "            'Children': 'Children',\n",
    "            'Alone': 'Alone',\n",
    "            'Husband': 'Husband',\n",
    "            'Other relatives': 'Other'\n",
    "        }\n",
    "\n",
    "        print(mapping)\n",
    "\n",
    "        data[target_col] = data[base_col].map(mapping)\n",
    "        cols_to_onehot.append(target_col)\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 'Base Area' to bin \n",
    "base_col = 'Base Area'\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False)\n",
    "levels_equal(data, base_col)\n",
    "\n",
    "try: \n",
    "    if cardinality == 'low': \n",
    "        target_col = 'basearea_fanfoss' # basearea_northbury\n",
    "        target_val = 'Fanfoss'\n",
    "        target_col_alt = 'basearea_northbury'\n",
    "        target_val_alt = 'Northbury'\n",
    "\n",
    "        print('\\nResult:')\n",
    "        data[target_col] = [1 if a == target_val else 0 for a in data[base_col]]\n",
    "\n",
    "        print('\\nAlternative result:')\n",
    "        test = data[['Income', base_col]].copy()\n",
    "        test[target_col_alt] = [1 if a == target_val_alt else 0 for a in test[base_col]]\n",
    "        sns.countplot(data=test, x=target_col_alt, hue='Income')\n",
    "        plt.show()\n",
    "        cols_bool.append(target_col)\n",
    "    elif cardinality == 'medium':\n",
    "        target_col = 'basearea'\n",
    "        data[target_col] = [\n",
    "            target_val if a == target_val \n",
    "            else target_val_alt if a == target_val_alt \n",
    "            else 'Rest' for a in data[base_col]]\n",
    "        cols_to_onehot.append(target_col)\n",
    "\n",
    "    elif cardinality == 'original':\n",
    "        target_col = 'basearea'\n",
    "        data[target_col] = data[base_col]\n",
    "        cols_to_onehot.append(target_col)\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "    \n",
    "sns.countplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Education Level \n",
    "base_col = 'Education Level'\n",
    "target_col = 'education'\n",
    "print(data.columns)\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False)\n",
    "levels_equal(data, base_col)\n",
    "\n",
    "edu_mapping = pd.read_csv(os.path.join(src_path, 'edu_mapping.csv'), sep=';')\n",
    "mapping_options = ['level_0', 'level_1', 'numeric', 'original', 'low']\n",
    "\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'low':\n",
    "        m_option = mapping_options[4]\n",
    "        plot_fct = sns.countplot\n",
    "    elif cardinality == 'medium': \n",
    "        m_option = mapping_options[4]\n",
    "        plot_fct = sns.countplot\n",
    "    elif cardinality == 'high': \n",
    "        m_option = mapping_options[2]\n",
    "        plot_fct = sns.histplot\n",
    "    elif cardinality == 'original':\n",
    "        m_option = mapping_options[3]\n",
    "        plot_fct = sns.countplot       \n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "\n",
    "\n",
    "#print(data[base_col].value_counts())\n",
    "\n",
    "#mapping = dict(edu_mapping[['name', mapping_options[2]]].set_index('name'))\n",
    "#mapping = {k:v for k,v in edu_mapping[['name', mapping_options[2]]].set_index('name').items()}\n",
    "#mapping = edu_mapping[['name', mapping_options[2]]].set_index('name')\n",
    "mapping = edu_mapping[['name', m_option]].rename(columns={m_option: target_col})\n",
    "print(mapping)\n",
    "\n",
    "# drop if reruning the cell \n",
    "if target_col in data.columns: \n",
    "    data.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "data = data.merge(mapping, left_on=base_col, right_on='name', how='left')\n",
    "data.drop(columns=['name'], inplace=True)  \n",
    "\n",
    "# plot target col against prediction classes\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plot_fct(data=data, x=target_col, hue='Income', ax=ax)\n",
    "#plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)\n",
    "\n",
    "\n",
    "data[[base_col, target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years of education \n",
    "base_col = 'Years of Education'\n",
    "target_col = 'education_years'\n",
    "#data.rename(columns={base_col: target_col}, inplace=True)\n",
    "data[target_col] = data[base_col]\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_numeric.append(target_col)\n",
    "data.head()\n",
    "sns.histplot(data=data, x=target_col, hue='Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Employment Sector\n",
    "base_col = 'Employment Sector'\n",
    "target_col = 'empl_sector'\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False)\n",
    "#levels_equal(data, base_col)\n",
    "\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'deprecated':\n",
    "        mapping = {\n",
    "            'Private Sector - Services ': 'private',\n",
    "            'Self-Employed (Individual)': 'self',\n",
    "            'Public Sector - Others': 'public',\n",
    "            '?': 'unknown',\n",
    "            'Private Sector - Others': 'private',\n",
    "            'Self-Employed (Company)': 'self',\n",
    "            'Public Sector - Government': 'public',\n",
    "            'Unemployed': 'delete',\n",
    "            'Never Worked': 'delete'\n",
    "            }\n",
    "\n",
    "    elif cardinality in ['low', 'medium', 'original']: \n",
    "        mapping = {\n",
    "            'Private Sector - Services ': 'private_services',\n",
    "            'Self-Employed (Individual)': 'self_individual',\n",
    "            'Public Sector - Others': 'public_others',\n",
    "            '?': 'unknown',\n",
    "            'Private Sector - Others': 'private_others',\n",
    "            'Self-Employed (Company)': 'self_company',\n",
    "            'Public Sector - Government': 'public_gov',\n",
    "            'Unemployed': 'unemployed',\n",
    "            'Never Worked': 'unemployed'\n",
    "            }\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "\n",
    "print(mapping)\n",
    "    \n",
    "data[target_col] = data[base_col].map(mapping)\n",
    "levels_equal(data, target_col)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "sns.countplot(data=data, x=target_col, hue='Income', ax=ax)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# role\n",
    "base_col = 'Role'\n",
    "target_col = 'empl_role'\n",
    "\n",
    "plot_feature_imp(data.loc[~data.Income.isna()], base_col, weighted=False)\n",
    "levels_equal(data, base_col)\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality in ['low', 'medium']:\n",
    "        mapping = {\n",
    "            'Professor': 'Professor',\n",
    "            'Management': 'Management',\n",
    "            'Repair & constructions': 'Operational_low',\n",
    "            'Administratives': 'Operational',\n",
    "            'Sales': 'Sales',\n",
    "            'Other services': 'Services',\n",
    "            'Machine Operators & Inspectors': 'Operational',\n",
    "            '?': 'unknown',\n",
    "            'Transports': 'Operational_low',\n",
    "            'Cleaners & Handlers': 'Cleaners',\n",
    "            'Agriculture and Fishing': 'Operational',\n",
    "            'IT': 'IT_Security',\n",
    "            'Security': 'IT_Security',\n",
    "            'Household Services': 'Household',\n",
    "            'Army': 'Operational_low'\n",
    "        }\n",
    "    elif cardinality == 'original':       \n",
    "        mapping = {\n",
    "            'Professor': 'Professor',\n",
    "            'Management': 'Management',\n",
    "            'Repair & constructions': 'Constructions',\n",
    "            'Administratives': 'Administratives',\n",
    "            'Sales': 'Sales',\n",
    "            'Other services': 'Services',\n",
    "            'Machine Operators & Inspectors': 'Operator',\n",
    "            '?': 'unknown',\n",
    "            'Transports': 'Transports',\n",
    "            'Cleaners & Handlers': 'Cleaners',\n",
    "            'Agriculture and Fishing': 'Agriculture',\n",
    "            'IT': 'IT', \n",
    "            'Security': 'Security',\n",
    "            'Household Services': 'Household',\n",
    "            'Army': 'Army'\n",
    "        }\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "print(data[base_col].value_counts())\n",
    "\n",
    "print(mapping)\n",
    "    \n",
    "data[target_col] = data[base_col].map(mapping)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "sns.countplot(data=data, x=target_col, hue='Income', ax=ax)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_to_onehot.append(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Working Hours per week\n",
    "base_col = 'Working Hours per week'\n",
    "target_col = 'working_hrs_week'\n",
    "\n",
    "data[target_col] = data[base_col]\n",
    "#data.rename(columns={base_col: target_col}, inplace=True)\n",
    "\n",
    "#setting working hours per week of those that have never worked or are unemployed to 0\n",
    "data.loc[data['empl_sector'] == 'unemployed', 'working_hrs_week'] = 0\n",
    "\n",
    "sns.histplot(data=data, x=target_col, hue='Income', bins=30)\n",
    "plt.show()\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "cols_numeric.append(target_col)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Money Received\n",
    "base_col = 'Money Received'\n",
    "target_col = 'group_b_received_money'\n",
    "\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'low':\n",
    "        data[target_col] = [1 if v != 0 else 0 for v in data[base_col]]\n",
    "        plot_fct = sns.countplot\n",
    "        cols_bool.append(target_col)\n",
    "    elif cardinality == 'original':\n",
    "        data[target_col] = data[base_col]\n",
    "        plot_fct = sns.histplot\n",
    "        cols_numeric.append(target_col)\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n",
    "\n",
    "plot_fct(data=data, x=target_col, hue='Income')\n",
    "plt.show()\n",
    "\n",
    "#data[[base_col, target_col]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "# Ticket Price\n",
    "base_col = 'Ticket Price'\n",
    "target_col = 'group_c_payed'\n",
    "\n",
    "#low, medium, high, original\n",
    "try: \n",
    "    if cardinality == 'low':\n",
    "        data[target_col] = [1 if v != 0 else 0 for v in data[base_col]]\n",
    "        sns.countplot(data=data, x=target_col, hue='Income')\n",
    "        cols_bool.append(target_col)\n",
    "    elif cardinality == 'original':\n",
    "        data[target_col] = data[base_col]\n",
    "        sns.histplot(data=data, x=target_col, hue='Income', bins = 30)\n",
    "        cols_numeric.append(target_col)\n",
    "    else: \n",
    "        raise NotImplementedError(f'Can not interpret cardinality \"{cardinality}\" for base feature \"{base_col}\"!')\n",
    "except Exception as e:\n",
    "    error_log['cleaning'].append(e)\n",
    "    raise Warning(e)\n",
    "    \n",
    "\n",
    "cols_to_drop.append(base_col)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#data[[base_col, target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors\n",
    "for name, log in error_log.items():\n",
    "    if len(log) > 0: \n",
    "        print(f'{name}:\\n {log}')\n",
    "        raise Warning('Errors occured! See above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols\n",
    "#cols_to_drop.append('CITIZEN_ID')\n",
    "col_with_index = ['CITIZEN_ID']\n",
    "data.drop(columns=cols_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = data.copy().set_index(col_with_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## profile report\n",
    "\n",
    "create_cleaning_report = False\n",
    "if create_cleaning_report: \n",
    "    profile = ProfileReport(\n",
    "        data,\n",
    "        title=f'Cleaned data {dataset_name}' ,\n",
    "        minimal=False, \n",
    "        correlations={\n",
    "        \"pearson\": {\"calculate\": True},\n",
    "        \"spearman\": {\"calculate\": False},\n",
    "        \"kendall\": {\"calculate\": False},\n",
    "        \"phi_k\": {\"calculate\": False},\n",
    "        \"cramers\": {\"calculate\": False},\n",
    "        }\n",
    "    )\n",
    "    profile.to_file(os.path.join(explorations_path, f'profile_data_cleaned_{dataset_name}.html'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = combined_data.copy().loc[combined_data.Income.isna()]\n",
    "test_data.drop(columns='Income', inplace=True)\n",
    "test_data.info()\n",
    "\n",
    "data = combined_data.copy().loc[~combined_data.Income.isna()]\n",
    "data.Income = data.Income.astype(int)\n",
    "data.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explorations = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape[1])\n",
    "data.shape[1] - (len(cols_numeric) + len(cols_bool) + len(cols_to_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check colmuns\n",
    "expected_ncols = len(cols_numeric) + len(cols_bool)\n",
    "for cat_col in cols_to_onehot: \n",
    "    expected_ncols += data[cat_col].nunique()\n",
    "    \n",
    "expected_ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cols_to_drop))\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target distribution\n",
    "\n",
    "sns.countplot(data=data, x='Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_explorations: \n",
    "    # Prepare figure\n",
    "    my_dpi = 200\n",
    "    fig = plt.figure(\n",
    "        figsize=(\n",
    "            #10, 8\n",
    "            1000/my_dpi, 1000/my_dpi\n",
    "        )\n",
    "    ) \n",
    "\n",
    "    # Obtain correlation matrix. Round the values to 2 decimal cases. Use the DataFrame corr() and round() method.\n",
    "    corr = np.round(data.corr(method=\"pearson\"), decimals=2)\n",
    "\n",
    "    # Build annotation matrix (values above |0.5| will appear annotated in the plot)\n",
    "    mask_annot = np.absolute(corr.values) >= 0.5\n",
    "    annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) # Try to understand what this np.where() does\n",
    "\n",
    "    # Plot heatmap of the correlation matrix\n",
    "    sns.heatmap(data=corr, annot=annot, cmap=sns.diverging_palette(220, 10, as_cmap=True), \n",
    "                fmt='s', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
    "\n",
    "    # Layout\n",
    "    fig.subplots_adjust(top=0.95)\n",
    "    # fig.suptitle(\"Correlation Matrix\", fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(explorations_path, 'correlation_matrix.png')\n",
    "        ,dpi=my_dpi\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions \n",
    "if plot_explorations: \n",
    "    plotdata = data.loc[:,cols_numeric + cols_bool]\n",
    "    ncols = 3\n",
    "    n_plots = plotdata.shape[1]\n",
    "    nrows = int(np.ceil(n_plots/ncols))\n",
    "\n",
    "\n",
    "    my_dpi = 200\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        ncols=ncols, nrows=nrows, \n",
    "        figsize=(\n",
    "            # 15,13\n",
    "            1200/my_dpi, 1000/my_dpi\n",
    "        )\n",
    "    )\n",
    "    col_no = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols): \n",
    "            if col_no < n_plots:\n",
    "                col = plotdata.columns[col_no]\n",
    "                print(col)\n",
    "                if data[col].dtype in [np.float, np.int]: \n",
    "                    sns.histplot(data=plotdata, hue=data.Income, x=col, ax=ax[i,j], bins=30).set_title(col)\n",
    "                else : \n",
    "                    sns.countplot(data=plotdata, hue=data.Income, x=col, ax=ax[i,j], dodge=True).set_title(col)\n",
    "                ax[i,j].tick_params(labelrotation=45)\n",
    "                col_no +=1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(explorations_path, 'distributions.png'), dpi=200)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep config\n",
    "\n",
    "prep_config = {\n",
    "    'overSampling': False, \n",
    "    'scale': 'minmax', # standard, minmax,\n",
    "    'feature_selection':False#'boruta'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the cleaned data into test and train data \n",
    "X_train = data.copy().drop(['Income'], axis=1)#.values\n",
    "y = data.copy().loc[:,'Income'].values\n",
    "\n",
    "X_test = test_data.copy()#.values\n",
    "X_test.shape\n",
    "\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('y.shape', y.shape)\n",
    "print('X_test.shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/feature-selection-with-borutapy-f0ea84c9366\n",
    "\n",
    "def onehot_scale(X_train, X_test, scaler, verbose=False): \n",
    "    ###Creating series for categorical test and train\n",
    "    X_train_bool = X_train[cols_bool]\n",
    "    X_test_bool = X_test[cols_bool]\n",
    "\n",
    "    ###Instantiating One Hot Encoder\n",
    "    ohe = OneHotEncoder()\n",
    "    ###Creating series for categorical test and train\n",
    "    X_train_cat = X_train[cols_to_onehot]\n",
    "    X_test_cat = X_test[cols_to_onehot]\n",
    "    ###Fitting encoder to training categorical features and transforming ###test and train\n",
    "    X_train_ohe = ohe.fit_transform(X_train_cat)\n",
    "    X_test_ohe = ohe.transform(X_test_cat)\n",
    "\n",
    "    ###Converting series to dataframes\n",
    "    columns = ohe.get_feature_names(input_features=X_train_cat.columns)\n",
    "    X_train_processed = pd.DataFrame(X_train_ohe.todense(), columns=columns, index=X_train_bool.index)\n",
    "    X_test_processed = pd.DataFrame(X_test_ohe.todense(), columns=columns, index=X_test_bool.index)\n",
    "\n",
    "\n",
    "    ###Instantiating Standard Scaler\n",
    "    if scaler == 'standard':        \n",
    "        ss = StandardScaler()\n",
    "    elif scaler == 'minmax': \n",
    "        ss = MinMaxScaler()\n",
    "    else: \n",
    "        raise ValueError(f'Can not interpret {scaler} as scaler!')\n",
    "\n",
    "    ###Converting continuous feature values to floats\n",
    "    X_train_cont = X_train[cols_numeric].astype(float)\n",
    "    X_test_cont = X_test[cols_numeric].astype(float)\n",
    "    ###Fitting scaler to training continuous features and transforming ###train and test\n",
    "    X_train_scaled = ss.fit_transform(X_train_cont)\n",
    "    X_test_scaled = ss.transform(X_test_cont)\n",
    "\n",
    "\n",
    "    ###Concatenating scaled and encoded dataframes\n",
    "    X = pd.concat([pd.DataFrame(X_train_scaled, index=X_train_bool.index), X_train_bool, X_train_processed], axis=1).values\n",
    "    X_test_ = pd.concat([pd.DataFrame(X_test_scaled, index=X_test_bool.index),X_test_bool, X_test_processed], axis=1).values\n",
    "    \n",
    "    if verbose: \n",
    "        print('X_train_scaled.shape', X_train_scaled.shape)\n",
    "        print('X_train_bool.shape', X_train_bool.shape)\n",
    "        print('X_train_processed.shape', X_train_processed.shape)\n",
    "\n",
    "        print('X.shape', X.shape)\n",
    "        print('y.shape', y.shape)\n",
    "        print('X_test.shape', X_test_.shape)\n",
    "    \n",
    "    return X, X_test_\n",
    "\n",
    "if True: \n",
    "    X, X_test_ = onehot_scale(X_train, X_test, scaler=prep_config['scale'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/scikit-learn-contrib/boruta_py\n",
    "# https://towardsdatascience.com/feature-selection-with-borutapy-f0ea84c9366\n",
    "\n",
    "\n",
    "# load X and y\n",
    "# NOTE BorutaPy accepts numpy arrays only, hence the .values attribute\n",
    "# X = pd.read_csv('examples/test_X.csv', index_col=0).values\n",
    "# y = pd.read_csv('examples/test_y.csv', header=None, index_col=0).values\n",
    "# y = y.ravel()\n",
    "\n",
    "if prep_config['feature_selection'] == 'boruta': \n",
    "\n",
    "\n",
    "    # define random forest classifier, with utilising all cores and\n",
    "    # sampling in proportion to y labels\n",
    "    rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "    # define Boruta feature selection method\n",
    "    feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=1)\n",
    "\n",
    "    # find all relevant features - 5 features should be selected\n",
    "    feat_selector.fit(X, y)\n",
    "\n",
    "    # check selected features - first 5 features are selected\n",
    "    print(feat_selector.support_)\n",
    "    # check ranking of features\n",
    "    print(feat_selector.ranking_)\n",
    "\n",
    "    # call transform() on X to filter it down to selected features\n",
    "    X_filtered = feat_selector.transform(X)\n",
    "    X_test_filtered = feat_selector.transform(X_test_)\n",
    "\n",
    "    \n",
    "    X_metadata = pd.DataFrame({\n",
    "    'Features': (X_train.drop('Income', axis=1).columns.to_list()),\n",
    "    'support': (feat_selector.support_), \n",
    "    'ranking': (feat_selector.ranking_)\n",
    "    })\n",
    "\n",
    "    X_metadata\n",
    "    \n",
    "    X_metadata.support.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overSampling to cope with class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split on updated X\n",
    "X_t, X_val, y_t, y_val = train_test_split(X, y, random_state=42, stratify=None)\n",
    "sns.countplot(y_t)\n",
    "plt.show()\n",
    "\n",
    "# https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "if prep_config['overSampling']: \n",
    "    sm = SMOTE(random_state=2, n_jobs=-1, k_neighbors=5, sampling_strategy='auto')\n",
    "    X_t, y_t = sm.fit_sample(X_t, y_t)\n",
    "    sns.countplot(y_t)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wich models to run\n",
    "modelling_config = {\n",
    "    'naive_bayes1': False,\n",
    "    'naive_bayes2': False,\n",
    "    'naive_bayes3': True,\n",
    "    'logistic_regression': False,\n",
    "    'knn': False,\n",
    "    'bagging_knn': False,\n",
    "    'svc': False,\n",
    "    'dt': False,\n",
    "    'random_forest': False, \n",
    "    'boosted_tree': False, \n",
    "    'boosted_tree_gs': False,\n",
    "    'boosted_tree_after_gs': False,\n",
    "    'mlp': False,\n",
    "    'mlp_gs': False,\n",
    "    'mlp_after_gs': False, \n",
    "    'ensemble1': False,\n",
    "    'ensemble2': False,\n",
    "    'adaboost': False,\n",
    "    'stacking1': False,\n",
    "    'stacking2' : False,\n",
    "    'stacking3' : False\n",
    "}\n",
    "\n",
    "model_comparison = [\n",
    "    'naive_bayes1',\n",
    "    'naive_bayes2',\n",
    "    'naive_bayes3',\n",
    "    'logistic_regression',\n",
    "    'knn',\n",
    "    'bagging_knn',\n",
    "    'svc',\n",
    "    'dt',\n",
    "    'random_forest', \n",
    "    'boosted_tree', \n",
    "    'boosted_tree_gs',\n",
    "    'boosted_tree_after_gs',\n",
    "    'mlp',\n",
    "    'mlp_gs',\n",
    "    'mlp_after_gs', \n",
    "    'ensemble1',\n",
    "    'ensemble2',\n",
    "    'adaboost',\n",
    "    'stacking1',\n",
    "    'stacking2',\n",
    "    'stacking3'\n",
    "]\n",
    "\n",
    "model_comparison = [\n",
    "    'naive_bayes1',\n",
    "    'naive_bayes2', \n",
    "    'naive_bayes3', \n",
    "    'ensemble1'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_csv(model, X_test_, test_data, file_no): \n",
    "    test_pred = model.predict(X_test_)\n",
    "    submission_df = pd.DataFrame({'Income':test_pred}, index=test_data.index).reset_index()\n",
    "    filename = f'Group26_Version{file_no}.csv'\n",
    "    submission_df.to_csv(os.path.join(submissions_path, filename), index=False)\n",
    "\n",
    "def train_model(model, params, X_t, y_t, X_val, y_val):\n",
    "    clf = model(random_state=0, verbose=False, **params)\n",
    "\n",
    "    clf.fit(X_t, y_t)\n",
    "    predicted = clf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    print('Acc:', clf.score(X_val, y_val))\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, params, X_t, y_t, X_val, y_val):\n",
    "    clf = model(**params)\n",
    "\n",
    "    clf.fit(X_t, y_t)\n",
    "    predicted = clf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    print('Acc:', clf.score(X_val, y_val))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Naive Bayes</font> <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Instantiating gaussian naive bayes\n",
    "naive_bayes1 = GaussianNB()\n",
    "\n",
    "if modelling_config['naive_bayes1']: \n",
    "    ###Fitting naive bayes to train\n",
    "    naive_bayes1.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = naive_bayes1.predict(X_val)\n",
    "    ###Training Score\n",
    "    naive_bayes1.score(X_t, y_t)\n",
    "    ###Test Score\n",
    "    naive_bayes1.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.48178571428571426\n",
    "    # f1_micro: 0.44875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Instantiating multinomial naive bayes\n",
    "naive_bayes2 = MultinomialNB()\n",
    "\n",
    "###used data scaled with minmax here \n",
    "if modelling_config['naive_bayes2'] and prep_config['scale'] == 'minmax': \n",
    "\n",
    "    ###Fitting naive bayes to train\n",
    "    naive_bayes2.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = naive_bayes2.predict(X_val)\n",
    "    ###Training Score\n",
    "    naive_bayes2.score(X_t, y_t)\n",
    "    ###Test Score\n",
    "    naive_bayes2.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8044642857142859\n",
    "\n",
    "\n",
    "###Instantiating complement naive bayes\n",
    "naive_bayes3 = ComplementNB()\n",
    "\n",
    "if modelling_config['naive_bayes3']: \n",
    "\n",
    "    ###Fitting naive bayes to train\n",
    "    naive_bayes3.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = naive_bayes3.predict(X_val)\n",
    "    ###Training Score\n",
    "    naive_bayes3.score(X_t, y_t)\n",
    "    ###Test Score\n",
    "    naive_bayes3.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.7673214285714286\n",
    "    \n",
    "    scores = cross_val_score(naive_bayes3, X, y, cv=10, scoring='f1_micro')\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    #0.7610267857142856 ~ 0.005905863622498532\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Logistic Regression</font> <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['logistic_regression']: \n",
    "    ###Instantiating logistic regression\n",
    "    log_model = LogisticRegression()\n",
    "    ###Fitting logistic regression to train\n",
    "    log_model.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = log_model.predict(X_val)\n",
    "    ###Training Score\n",
    "    log_model.score(X_t,y_t)\n",
    "    ###Test Score\n",
    "    log_model.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8528571428571429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['logistic_regression']: \n",
    "    model = LogisticRegression(random_state=0, verbose=False)\n",
    "    f1w = make_scorer(f1_score, average='micro')\n",
    "\n",
    "\n",
    "    parameter_space = {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': list(range(1,10)),\n",
    "        'class_weight':[{0:1.0, 1:1.0},{0:1.0, 1:50.0}],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'multi_class':['auto','ovr','multinomial']\n",
    "        #dual\n",
    "        #tolerance for stopping criteria\n",
    "        #max_iter\n",
    "        #refit\n",
    "        #intercept_scaling\n",
    "        #l1_ratios\n",
    "    }\n",
    "\n",
    "    lr_gs = GridSearchCV(model, parameter_space, n_jobs=-1, scoring=f1w, cv=5, verbose=10)\n",
    "\n",
    "    lr_gs.fit(X_t, y_t)\n",
    "\n",
    "    print(f'{lr_gs.scoring}: {lr_gs.best_score_}')\n",
    "    # make_scorer(f1_score, average=micro): 0.85\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_gs.best_params_\n",
    "#{'C': 1,\n",
    "# 'class_weight': {0: 1.0, 1: 1.0},\n",
    "# 'multi_class': 'auto',\n",
    "# 'penalty': 'l2',\n",
    "# 'solver': 'liblinear'}\n",
    "lr = LogisticRegression(C=1,class_weight={0: 1.0, 1: 1.0},penalty = 'l2',solver='liblinear',multi_class='auto')\n",
    "\n",
    "if modelling_config['logistic_regression']: \n",
    "    lr_params_short = {\n",
    "        'C': 1,\n",
    "        'class_weight': {0: 1.0, 1: 1.0},\n",
    "        'penalty': 'l2',\n",
    "        'solver': 'liblinear',\n",
    "        'multi_class': 'auto'\n",
    "    }\n",
    "\n",
    "    # train final model with best_params from grid search \n",
    "    lr = train_model(\n",
    "        LogisticRegression,\n",
    "        lr_params_short,\n",
    "    #   lr_gs.best_params_,\n",
    "        X_t, y_t, X_val, y_val\n",
    "    )\n",
    "    # f1_micro: 0.8530357142857142\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        lr, X_val, y_val, cv=10, scoring='f1_micro'\n",
    "    )\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    # 0.8510714285714286 ~ 0.008151937293223808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Randomized Search\n",
    "\n",
    "if modelling_config['logistic_regression']: \n",
    "    rsearch = RandomizedSearchCV(estimator=LogisticRegression(random_state=0, verbose=False), param_distributions=parameter_space, n_iter=100)\n",
    "    rsearch.fit(X_t, y_t)\n",
    "    # rsearch.best_score_): 0.8498809523809523\n",
    "    lr_params_short = {\n",
    "        'C': 6,\n",
    "        'class_weight': {0: 1.0, 1: 1.0},\n",
    "        'penalty': 'l2',\n",
    "        'solver': 'saga',\n",
    "        'multi_class': 'ovr'\n",
    "    }\n",
    "\n",
    "    # train final model with best_params from grid search \n",
    "    lr = train_model(\n",
    "        LogisticRegression,\n",
    "        lr_params_short,\n",
    "    #   rsearch.best_params_ : {'solver': 'saga','penalty': 'l2','multi_class': 'ovr','class_weight': {0: 1.0, 1: 1.0},'C': 6}\n",
    "        X_t, y_t, X_val, y_val\n",
    "    )\n",
    "    # f1_micro: 0.8528571428571429\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        lr, X_val, y_val, cv=10, scoring='f1_micro'\n",
    "    )\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    # 0.8514285714285714 ~ 0.008329931278350444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>KNN</font> <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['knn']: \n",
    "    ###Instantiating k nearest neighbors \n",
    "    KNNmodel = KNeighborsClassifier()\n",
    "    ###Fitting k nearnest neighbors to train\n",
    "    KNNmodel.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = KNNmodel.predict(X_val)\n",
    "    ###Training Score\n",
    "    KNNmodel.score(X_t,y_t)\n",
    "    ###Test Score\n",
    "    KNNmodel.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8351785714285714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['knn']: \n",
    "    model = KNeighborsClassifier()\n",
    "    f1w = make_scorer(f1_score, average='micro')\n",
    "\n",
    "\n",
    "    parameter_space = {\n",
    "        'n_neighbors': list(range(1,15)),\n",
    "        'weights': ['uniform','distance'],\n",
    "        'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size' : [5,10,15,30,45] \n",
    "    }\n",
    "\n",
    "    knn_gs = GridSearchCV(model, parameter_space, n_jobs=-1, scoring=f1w, cv=5, verbose=10)\n",
    "\n",
    "    knn_gs.fit(X_t, y_t)\n",
    "\n",
    "    print(f'{knn_gs.scoring}: {knn_gs.best_score_}')\n",
    "    # make_scorer(f1_score, average=micro): 0.8419047619047619\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_gs.best_params_\n",
    "#{'algorithm': 'brute',\n",
    "# 'leaf_size': 15,\n",
    "# 'n_neighbors': 11,\n",
    "# 'weights': 'uniform'}\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_neighbors = 11, weights = 'uniform')\n",
    "\n",
    "if modelling_config['knn']: \n",
    "    knn_params_short = {\n",
    "        'algorithm': 'brute',\n",
    "        'n_neighbors': 11,\n",
    "        'weights': 'uniform'\n",
    "    }\n",
    "\n",
    "    # train final model with best_params from grid search \n",
    "    knn = train_model_simple(\n",
    "        KNeighborsClassifier,\n",
    "        knn_params_short,\n",
    "    #   knn_gs.best_params_,\n",
    "        X_t, y_t, X_val, y_val\n",
    "    )\n",
    "    # f1_micro: 0.8483928571428572\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        knn, X_val, y_val, cv=10, scoring='f1_micro'\n",
    "    )\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    # 0.8396428571428572 ~ 0.008096988606253283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging knn\n",
    "if modelling_config['bagging_knn']: \n",
    "    ###Instantiating k nearest neighbors \n",
    "    bagging_knn = BaggingClassifier(base_estimator = knn, random_state = 0)\n",
    "    ###Fitting k nearnest neighbors to train\n",
    "    bagging_knn.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = bagging_knn.predict(X_val)\n",
    "    ###Training Score\n",
    "    bagging_knn.score(X_t,y_t)\n",
    "    ###Test Score\n",
    "    bagging_knn.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8469642857142857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Support Vector Machine</font> <a class=\"anchor\" id=\"fourth-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['svc']: \n",
    "    ###Instantiating support vector classifier\n",
    "    svc_model = SVC(gamma='scale')\n",
    "    ###Fitting logistic regression to train\n",
    "    svc_model.fit(X_t,y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = svc_model.predict(X_val)\n",
    "    ###Training Score\n",
    "    svc_model.score(X_t,y_t)\n",
    "    ###Test Score\n",
    "    svc_model.score(X_val,y_val)\n",
    "    \n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['svc']: \n",
    "    model = SVC()\n",
    "    f1w = make_scorer(f1_score, average='micro')\n",
    "\n",
    "\n",
    "    parameter_space = {\n",
    "        'C': [0.1,0.5,1,10,100],\n",
    "        'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    svc_gs = GridSearchCV(model, parameter_space, n_jobs=-1, scoring=f1w, cv=5, verbose=10)\n",
    "\n",
    "    svc_gs.fit(X_t, y_t)\n",
    "\n",
    "    print(f'{svc_gs.scoring}: {svc_gs.best_score_}')\n",
    "    # make_scorer(f1_score, average=micro): 0.85375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_gs.best_params_\n",
    "#{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "svc = SVC(C = 1, gamma = 'scale', kernel = 'rbf', random_state=0, verbose=False, probability = True)\n",
    "\n",
    "\n",
    "if modelling_config['svc']: \n",
    "    svc_params_short = {\n",
    "        'C': 1,\n",
    "        'gamma': 'scale',\n",
    "        'kernel': 'rbf'\n",
    "    }\n",
    "\n",
    "    # train final model with best_params from grid search \n",
    "    svc = train_model(\n",
    "        SVC,\n",
    "        svc_params_short,\n",
    "    #   svc_gs.best_params_,\n",
    "        X_t, y_t, X_val, y_val\n",
    "    )\n",
    "    # f1_micro:0.8625\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        svc, X_val, y_val, cv=10, scoring='f1_micro'\n",
    "    )\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    # 0.8551785714285713 ~ 0.012511474325430974"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Decision Trees</font> <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['dt']: \n",
    "    ###Instantiating Decision Tree Classifier\n",
    "    dt = DecisionTreeClassifier()\n",
    "    ###Fitting Decision Tree Classifier to train and test\n",
    "    dt.fit(X_t, y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = dt.predict(X_val)\n",
    "    ###Test Score\n",
    "    dt.score(X_val, y_val)\n",
    "    ###Training Score\n",
    "    dt.score(X_t, y_t)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8139285714285716"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Random Forest</font> <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_jobs=-1, n_estimators=500, oob_score=True, max_depth=6, random_state=42)\n",
    "\n",
    "if modelling_config['random_forest']: \n",
    "    ###Instantiating Random Forest Classifier\n",
    "    ###Fitting Random Forest Classifier to train and test\n",
    "    rf2.fit(X_t, y_t)\n",
    "    ###Predicting on test data\n",
    "    predicted = rf2.predict(X_val)\n",
    "    ###Test Score\n",
    "    rf2.score(X_val, y_val)\n",
    "    ###Training Score\n",
    "    rf2.score(X_t, y_t)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8482142857142857\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Boosted Trees</font> <a class=\"anchor\" id=\"seventh-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GradientBoostingClassifier(\n",
    "    learning_rate=.1,\n",
    "    random_state=0, verbose=False,\n",
    "    subsample=1,\n",
    "    n_estimators=1000, max_depth=7, min_impurity_decrease = 0.1,\n",
    "    max_features='auto',\n",
    "    n_iter_no_change=30, validation_fraction=0.1,\n",
    "    warm_start=False\n",
    ")\n",
    "\n",
    "if modelling_config['boosted_tree']: \n",
    "    clf1.fit(X_t, y_t)\n",
    "    predicted = clf1.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "    print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "    # f1_micro: 0.8755357142857143\n",
    "    print('Acc:', clf1.score(X_val, y_val))\n",
    "\n",
    "    save_submission_csv(clf1, X_test_, test_data, '12')\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "    clf1, X, y, cv=10, scoring='f1_micro'\n",
    "    )\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    # 0.8708482142857144 ~ 0.006533890504710872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if modelling_config['boosted_tree_gs']: \n",
    "    model = GradientBoostingClassifier(random_state=0, verbose=False)\n",
    "    f1w = make_scorer(f1_score, average='micro')\n",
    "\n",
    "\n",
    "    parameter_space = {\n",
    "        'learning_rate':[.1, .05],\n",
    "        'subsample':[1, .9],\n",
    "        'n_estimators':[1000], \n",
    "        'min_samples_split': [2,3],\n",
    "        'max_depth': list(range(5,9)), \n",
    "        'min_impurity_decrease': [0.0, 0.1],\n",
    "        'max_features': ['auto', None],\n",
    "        'n_iter_no_change': [30],\n",
    "        'validation_fraction': [0.1],\n",
    "        'warm_start': [False], \n",
    "        'ccp_alpha': [0.0]\n",
    "    }\n",
    "\n",
    "\n",
    "    clf_gs = GridSearchCV(model, parameter_space, n_jobs=-1, scoring=f1w, cv=5, verbose=10)\n",
    "\n",
    "    clf_gs.fit(X, y)\n",
    "\n",
    "    print(f'{clf_gs.scoring}: {clf_gs.best_score_}')\n",
    "    # make_scorer(f1_score, average=micro): 0.8710267857142856\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf3.get_params()\n",
    "\n",
    "if modelling_config['boosted_tree_after_gs']: \n",
    "    clf3_params_short = {\n",
    "        'ccp_alpha': 0.0,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'max_features': 'auto',\n",
    "        'min_impurity_decrease': 0.1,\n",
    "        'min_samples_split': 3,\n",
    "        'n_estimators': 1000,\n",
    "        'n_iter_no_change': 30,\n",
    "        'subsample': 1,\n",
    "        'validation_fraction': 0.1,\n",
    "        'warm_start': False\n",
    "    }\n",
    "\n",
    "    # train final model with best_params from grid search \n",
    "    clf3 = train_model(\n",
    "        GradientBoostingClassifier,\n",
    "        clf3_params_short,\n",
    "    #   clf_gs.best_params_,\n",
    "        X_t, y_t, X_val, y_val\n",
    "    )\n",
    "    # f1_micro: 0.8753571428571428\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        clf3, X, y, cv=10, scoring='f1_micro'\n",
    "    )\n",
    "    print(f'{scores.mean()} ~ {scores.std()}')\n",
    "    # 0.8708482142857144 ~ 0.007379047013092432\n",
    "\n",
    "    # save\n",
    "    save_submission_csv(clf3, X_test_, test_data, '11')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Neural Networks</font> <a class=\"anchor\" id=\"eighth-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['mlp']: \n",
    "        model = MLPClassifier(\n",
    "            alpha=0.000001,\n",
    "            activation='relu', # [tanh, relu]\n",
    "            random_state=0, verbose=False, \n",
    "            hidden_layer_sizes = (100, ),# [(100,), (50,50), (200,)]\n",
    "            max_iter=1000, early_stopping=True, \n",
    "            learning_rate_init = 0.001,  # [0.05, 0.001, 0.005]\n",
    "            learning_rate='constant', # ['invscaling', 'constant']\n",
    "            momentum=0.9, #[0.8, 0.9]\n",
    "            solver='adam', # ['adma', 'sgd']\n",
    "            beta_1 = .9, #[.7, .8, .9]\n",
    "            beta_2 = .999 #[.9, .99, .8]\n",
    "        )\n",
    "        model.fit(X_t, y_t)\n",
    "        predicted = model.predict(X_val)\n",
    "\n",
    "        print(classification_report(y_val, predicted))\n",
    "        print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "        # f1_micro: 0.8614285714285714\n",
    "        print('Acc:', model.score(X_val, y_val))\n",
    "        \n",
    "        if True: \n",
    "                scores = cross_val_score(\n",
    "                model, X, y, cv=5, scoring='f1_micro'\n",
    "                )\n",
    "                print(f'{scores.mean()} ~ {scores.std()}')\n",
    "                # 0.8549107142857144 ~ 0.004171181652427915\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if modelling_config['mlp_gs']: \n",
    "    model = MLPClassifier(random_state=0, verbose=False, max_iter=1000, early_stopping=True)\n",
    "    f1w = make_scorer(f1_score, average='micro')\n",
    "   \n",
    "    params = {\n",
    "        'alpha': (10.0 ** -np.arange(1, 7)).tolist(), \n",
    "        'activation': ['tanh', 'relu'],  \n",
    "        'hidden_layer_sizes': [(100,), (50,50), (200,), (50,50, 50 )], \n",
    "        'learning_rate_init': [0.05, 0.001, 0.005],\n",
    "        'learning_rate':['adaptive', 'constant'], \n",
    "        'momentum':[0.8, 0.9], \n",
    "        'solver': ['adam'], #['adma', 'sgd']\n",
    "        'beta_1': [.7, .8, .9], \n",
    "        'beta_2':[.9, .99, .8]\n",
    "    }\n",
    "\n",
    "\n",
    "    mlp_gs = GridSearchCV(model, params, n_jobs=-1, scoring=f1w, cv=5, verbose=10)\n",
    "\n",
    "    mlp_gs.fit(X, y)\n",
    "\n",
    "    print(f'{mlp_gs.scoring}: {mlp_gs.best_score_}')\n",
    "    #make_scorer(f1_score, average=micro): 0.8584375\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_gs_best_params = {\n",
    "    'activation': 'tanh',\n",
    "    'alpha': 0.0001,\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.8,\n",
    "    'hidden_layer_sizes': (50, 50, 50),\n",
    "    'learning_rate': 'adaptive',\n",
    "    'learning_rate_init': 0.001,\n",
    "    'momentum': 0.8,\n",
    "    'solver': 'adam'\n",
    "}\n",
    "\n",
    "mlp_after_gs = MLPClassifier(random_state=0, verbose=False, max_iter=1000, early_stopping=True, **mlp_gs_best_params)\n",
    "\n",
    "\n",
    "if modelling_config['mlp_after_gs']: \n",
    "        mlp_after_gs.fit(X_t, y_t)\n",
    "        predicted = mlp_after_gs.predict(X_val)\n",
    "\n",
    "        print(classification_report(y_val, predicted))\n",
    "        print('f1_micro:', f1_score(y_val, predicted, average='micro')) \n",
    "        # f1_micro: 0.8546428571428571\n",
    "        print('Acc:', mlp_after_gs.score(X_val, y_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#E8800A'>Ensembles</font> <a class=\"anchor\" id=\"ninth-bullet\"></a>\n",
    "  [Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble1 = VotingClassifier(\n",
    "    estimators=[('rf', rf2), ('gbt', clf1), ('mlp', mlp_after_gs)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "if modelling_config['ensemble1']: \n",
    "    ensemble1.fit(X_t, y_t)\n",
    "    predicted = ensemble1.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "\n",
    "    ensemble1.score(X_val, y_val)\n",
    "    \n",
    "    if True:\n",
    "        scores = cross_val_score(\n",
    "            ensemble1, X, y, cv=5, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')\n",
    "        #0.8653125000000002 ~ 0.0036202026665559423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['ensemble2']: \n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[('gbt', clf1), ('svc', svc)],\n",
    "        voting='soft')\n",
    "\n",
    "    eclf.fit(X_t, y_t)\n",
    "    predicted = eclf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "\n",
    "    eclf.score(X_val, y_val)\n",
    "    \n",
    "    if True:\n",
    "        scores = cross_val_score(\n",
    "            eclf, X, y, cv=5, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')\n",
    "        #0.8668750000000001 ~ 0.004359484148476345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelling_config['adaboost']: \n",
    "    ab = AdaBoostClassifier(random_state = 5)\n",
    "\n",
    "    ab.fit(X_t, y_t)\n",
    "    predicted = ab.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "\n",
    "    ab.score(X_val, y_val)\n",
    "    \n",
    "    if True:\n",
    "        scores = cross_val_score(\n",
    "            ab, X, y, cv=5, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')\n",
    "        # 0.8580357142857145 ~ 0.004430677062785573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if modelling_config['stacking1']: \n",
    "    estimators = [('gbt', clf1), ('mlp', mlp_after_gs)]\n",
    "    sc = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "    sc.fit(X_t, y_t)\n",
    "    predicted = sc.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "\n",
    "    sc.score(X_val, y_val)\n",
    "    \n",
    "    if True:\n",
    "        scores = cross_val_score(\n",
    "            sc, X, y, cv=5, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')\n",
    "        #0.8653125000000002 ~ 0.0036202026665559423\n",
    "        \n",
    "    save_submission_csv(sc, X_test_, test_data, '13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if modelling_config['stacking2']: \n",
    "    sclf = StackingClassifier(\n",
    "        estimators=[('gbt', clf1), ('mlp', mlp_after_gs)],\n",
    "        final_estimator=svc)\n",
    "\n",
    "    sclf.fit(X_t, y_t)\n",
    "    predicted = sclf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "\n",
    "    sclf.score(X_val, y_val)\n",
    "    \n",
    "    if True:\n",
    "        scores = cross_val_score(\n",
    "            sclf, X, y, cv=5, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')\n",
    "        # 0.8708482142857144 ~ 0.003944266537698527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if modelling_config['stacking3']: \n",
    "    sclf = StackingClassifier(\n",
    "        estimators=[('rf', rf2), ('gbt', clf1), ('mlp', mlp_after_gs), ('knn', knn)],\n",
    "        final_estimator=svc)\n",
    "\n",
    "    sclf.fit(X_t, y_t)\n",
    "    predicted = sclf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, predicted))\n",
    "\n",
    "    sclf.score(X_val, y_val)\n",
    "    \n",
    "    if True:\n",
    "        scores = cross_val_score(\n",
    "            sclf, X, y, cv=5, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')\n",
    "        # 0.8710714285714285 ~ 0.004056363104143051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: \n",
    "    for model in model_comparison:\n",
    "        model_inst = globals()[model]\n",
    "\n",
    "        print(model_inst)\n",
    "        scores = cross_val_score(\n",
    "            model_inst, X, y, cv=10, scoring='f1_micro'\n",
    "        )\n",
    "        print(f'{scores.mean()} ~ {scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
